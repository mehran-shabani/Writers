# Ù…Ø³ØªÙ†Ø¯Ø§Øª Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯ Ùˆ Ù„Ø§Ú¯â€ŒÚ¯Ø°Ø§Ø±ÛŒ

Ø§ÛŒÙ† Ø³Ù†Ø¯ Ø³ÛŒØ³ØªÙ… Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯ØŒ Ù„Ø§Ú¯â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ùˆ Ù‡Ø´Ø¯Ø§Ø±Ù‡Ø§ Ø¯Ø± Ø³ÛŒØ³ØªÙ… Writers Ø±Ø§ ØªÙˆØ¶ÛŒØ­ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯.

## ğŸ¯ Ù†Ù…Ø§ÛŒ Ú©Ù„ÛŒ

Ø³ÛŒØ³ØªÙ… Writers Ø§Ø² ÛŒÚ© Stack Ú©Ø§Ù…Ù„ Ø¨Ø±Ø§ÛŒ Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯ Ùˆ Ù„Ø§Ú¯â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯:

- **Prometheus**: Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§
- **Grafana**: Ù†Ù…Ø§ÛŒØ´ Ø¨ØµØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
- **Loki**: Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ùˆ query Ù„Ø§Ú¯â€ŒÙ‡Ø§
- **Promtail**: Ø§Ø±Ø³Ø§Ù„ Ù„Ø§Ú¯â€ŒÙ‡Ø§ Ø¨Ù‡ Loki
- **Alertmanager**: Ù…Ø¯ÛŒØ±ÛŒØª Ù‡Ø´Ø¯Ø§Ø±Ù‡Ø§
- **Exporters**: Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù

## ğŸ”§ Ù†ØµØ¨ Ùˆ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ

### Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø¨Ø§ Docker Compose

```bash
cd infrastructure

# Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ monitoring stack
docker-compose -f docker-compose.monitoring.yml up -d

# ÛŒØ§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§Ø³Ú©Ø±ÛŒÙ¾Øª
sudo bash scripts/setup-monitoring.sh
```

### Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ DashboardÙ‡Ø§

Ù¾Ø³ Ø§Ø² Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ:

- **Prometheus**: http://localhost:9090
- **Grafana**: http://localhost:3001 (admin/admin)
- **Alertmanager**: http://localhost:9093

## ğŸ“Š Prometheus

### Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø´Ø¯Ù‡

#### Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Application (FastAPI)

```python
# Ø¯Ø± backend/app/main.py
from prometheus_fastapi_instrumentator import Instrumentator

Instrumentator().instrument(app).expose(app)
```

Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯:

```
# HTTP Requests
http_requests_total{method="GET", path="/api/tasks", status="200"}

# Request Duration
http_request_duration_seconds_bucket{le="0.1", method="GET", path="/api/tasks"}

# In-Progress Requests
http_requests_inprogress{method="GET", path="/api/tasks"}
```

#### Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ø³ÛŒØ³ØªÙ… (Node Exporter)

```
# CPU
node_cpu_seconds_total
node_load1
node_load5
node_load15

# Memory
node_memory_MemTotal_bytes
node_memory_MemAvailable_bytes
node_memory_MemFree_bytes

# Disk
node_filesystem_avail_bytes
node_filesystem_size_bytes
node_disk_io_time_seconds_total

# Network
node_network_receive_bytes_total
node_network_transmit_bytes_total
```

#### Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ PostgreSQL

```
# Connections
pg_stat_database_numbackends

# Transactions
pg_stat_database_xact_commit
pg_stat_database_xact_rollback

# Locks
pg_locks_count

# Database Size
pg_database_size_bytes
```

#### Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Redis

```
# Memory
redis_memory_used_bytes
redis_memory_max_bytes

# Commands
redis_commands_processed_total
redis_commands_duration_seconds_total

# Keys
redis_db_keys
redis_db_keys_expiring

# Connections
redis_connected_clients
```

### Queryâ€ŒÙ‡Ø§ÛŒ Ù…ÙÛŒØ¯ Prometheus

```promql
# Ù†Ø±Ø® Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§ÛŒ HTTP
rate(http_requests_total[5m])

# Ù…ØªÙˆØ³Ø· Ø²Ù…Ø§Ù† Ù¾Ø§Ø³Ø®
rate(http_request_duration_seconds_sum[5m]) / rate(http_request_duration_seconds_count[5m])

# Ù†Ø±Ø® Ø®Ø·Ø§
rate(http_requests_total{status=~"5.."}[5m])

# Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² CPU
100 - (avg by (instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)

# Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² RAM
(node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100

# ÙØ¶Ø§ÛŒ Ø¯ÛŒØ³Ú© Ø¨Ø§Ù‚ÛŒâ€ŒÙ…Ø§Ù†Ø¯Ù‡
(node_filesystem_avail_bytes / node_filesystem_size_bytes) * 100
```

### Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Prometheus

ÙØ§ÛŒÙ„ `prometheus.yml`:

```yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s
  external_labels:
    cluster: 'writers-cluster'
    environment: 'production'

# Alertmanager configuration
alerting:
  alertmanagers:
    - static_configs:
        - targets: ['alertmanager:9093']

# Load rules
rule_files:
  - '/etc/prometheus/alerts/*.yml'

# Scrape configurations
scrape_configs:
  # Backend metrics
  - job_name: 'writers-backend'
    static_configs:
      - targets: ['backend:8000']
    metrics_path: '/metrics'

  # Node Exporter (system metrics)
  - job_name: 'node-exporter'
    static_configs:
      - targets: ['node-exporter:9100']

  # PostgreSQL Exporter
  - job_name: 'postgres-exporter'
    static_configs:
      - targets: ['postgres-exporter:9187']

  # Redis Exporter
  - job_name: 'redis-exporter'
    static_configs:
      - targets: ['redis-exporter:9121']

  # Nginx Exporter
  - job_name: 'nginx-exporter'
    static_configs:
      - targets: ['nginx-exporter:9113']
```

## ğŸ“ˆ Grafana

### ÙˆØ±ÙˆØ¯ Ø§ÙˆÙ„ÛŒÙ‡

1. Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ http://localhost:3001
2. ÙˆØ±ÙˆØ¯ Ø¨Ø§ admin/admin
3. ØªØºÛŒÛŒØ± Ø±Ù…Ø² Ø¹Ø¨ÙˆØ±

### Datasources

Datasourceâ€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ± Ø¨Ù‡ ØµÙˆØ±Øª Ø®ÙˆØ¯Ú©Ø§Ø± ØªÙ†Ø¸ÛŒÙ… Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯:

#### Prometheus
```yaml
name: Prometheus
type: prometheus
url: http://prometheus:9090
access: proxy
isDefault: true
```

#### Loki
```yaml
name: Loki
type: loki
url: http://loki:3100
access: proxy
```

### Dashboards Ø¢Ù…Ø§Ø¯Ù‡

#### 1. System Overview Dashboard

Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡:
- CPU Usage
- Memory Usage
- Disk Space
- Network Traffic
- System Load

```json
{
  "dashboard": {
    "title": "System Overview",
    "panels": [
      {
        "title": "CPU Usage",
        "targets": [
          {
            "expr": "100 - (avg(irate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100)"
          }
        ]
      }
    ]
  }
}
```

#### 2. Application Performance Dashboard

Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡:
- Request Rate
- Response Time (p50, p95, p99)
- Error Rate
- Active Requests

#### 3. Database Performance Dashboard

Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡:
- Active Connections
- Transaction Rate
- Query Duration
- Database Size
- Cache Hit Ratio

#### 4. Redis Performance Dashboard

Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡:
- Memory Usage
- Commands/sec
- Hit Rate
- Connected Clients
- Key Count

### Ø§ÛŒØ¬Ø§Ø¯ Dashboard Ø³ÙØ§Ø±Ø´ÛŒ

```bash
# Export dashboard
curl -H "Authorization: Bearer <api_key>" \
  http://localhost:3001/api/dashboards/uid/<dashboard_uid> > dashboard.json

# Import dashboard
curl -X POST \
  -H "Authorization: Bearer <api_key>" \
  -H "Content-Type: application/json" \
  -d @dashboard.json \
  http://localhost:3001/api/dashboards/db
```

## ğŸ“ Loki (Log Aggregation)

### Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Loki

ÙØ§ÛŒÙ„ `loki-config.yml`:

```yaml
auth_enabled: false

server:
  http_listen_port: 3100

ingester:
  lifecycler:
    address: 127.0.0.1
    ring:
      kvstore:
        store: inmemory
      replication_factor: 1
  chunk_idle_period: 5m
  chunk_retain_period: 30s

schema_config:
  configs:
    - from: 2024-01-01
      store: boltdb-shipper
      object_store: filesystem
      schema: v11
      index:
        prefix: index_
        period: 24h

storage_config:
  boltdb_shipper:
    active_index_directory: /loki/index
    cache_location: /loki/cache
    shared_store: filesystem
  filesystem:
    directory: /loki/chunks

limits_config:
  enforce_metric_name: false
  reject_old_samples: true
  reject_old_samples_max_age: 168h

chunk_store_config:
  max_look_back_period: 0s

table_manager:
  retention_deletes_enabled: true
  retention_period: 168h
```

### Promtail (Log Collector)

ÙØ§ÛŒÙ„ `promtail-config.yml`:

```yaml
server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: /tmp/positions.yaml

clients:
  - url: http://loki:3100/loki/api/v1/push

scrape_configs:
  # Backend logs
  - job_name: writers-backend
    static_configs:
      - targets:
          - localhost
        labels:
          job: writers-backend
          __path__: /var/log/writers/backend/*.log

  # Frontend logs
  - job_name: writers-frontend
    static_configs:
      - targets:
          - localhost
        labels:
          job: writers-frontend
          __path__: /var/log/writers/frontend/*.log

  # Worker logs
  - job_name: writers-worker
    static_configs:
      - targets:
          - localhost
        labels:
          job: writers-worker
          __path__: /var/log/writers/worker/*.log

  # Nginx logs
  - job_name: nginx
    static_configs:
      - targets:
          - localhost
        labels:
          job: nginx
          __path__: /var/log/nginx/*log
```

### Queryâ€ŒÙ‡Ø§ÛŒ Ù…ÙÛŒØ¯ Loki

```logql
# ØªÙ…Ø§Ù… Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ Backend
{job="writers-backend"}

# Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ Ø®Ø·Ø§
{job="writers-backend"} |= "ERROR"

# Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ Ø¨Ø§ pattern Ø®Ø§Øµ
{job="writers-backend"} |~ "user.*login"

# ØªØ¹Ø¯Ø§Ø¯ Ø®Ø·Ø§Ù‡Ø§ Ø¯Ø± 5 Ø¯Ù‚ÛŒÙ‚Ù‡ Ø§Ø®ÛŒØ±
sum(count_over_time({job="writers-backend"} |= "ERROR" [5m]))

# Ù†Ø±Ø® Ø®Ø·Ø§
rate({job="writers-backend"} |= "ERROR" [5m])

# Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ JSON parsed
{job="writers-backend"} | json | level="error"
```

## ğŸš¨ Alertmanager

### Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Alertmanager

ÙØ§ÛŒÙ„ `alertmanager.yml`:

```yaml
global:
  resolve_timeout: 5m
  smtp_smarthost: 'smtp.gmail.com:587'
  smtp_from: 'alerts@yourdomain.com'
  smtp_auth_username: 'alerts@yourdomain.com'
  smtp_auth_password: 'your_password'

route:
  group_by: ['alertname', 'cluster', 'service']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 12h
  receiver: 'email-notifications'
  
  routes:
    # Critical alerts -> immediate notification
    - match:
        severity: critical
      receiver: 'critical-notifications'
      continue: true
    
    # Warning alerts -> grouped notification
    - match:
        severity: warning
      receiver: 'warning-notifications'
      group_wait: 30s

receivers:
  - name: 'email-notifications'
    email_configs:
      - to: 'team@yourdomain.com'
        headers:
          Subject: '[Writers] Alert: {{ .GroupLabels.alertname }}'

  - name: 'critical-notifications'
    email_configs:
      - to: 'oncall@yourdomain.com'
        headers:
          Subject: '[CRITICAL] {{ .GroupLabels.alertname }}'
    # Slack webhook (optional)
    slack_configs:
      - api_url: 'https://hooks.slack.com/services/YOUR/WEBHOOK/URL'
        channel: '#alerts'
        title: 'Critical Alert'

  - name: 'warning-notifications'
    email_configs:
      - to: 'team@yourdomain.com'

inhibit_rules:
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'cluster', 'service']
```

### Ù‚ÙˆØ§Ù†ÛŒÙ† Ù‡Ø´Ø¯Ø§Ø± (Alert Rules)

ÙØ§ÛŒÙ„ `alerts/application.yml`:

```yaml
groups:
  - name: application_alerts
    interval: 30s
    rules:
      # High Error Rate
      - alert: HighErrorRate
        expr: |
          (sum(rate(http_requests_total{status=~"5.."}[5m])) by (job)
          /
          sum(rate(http_requests_total[5m])) by (job)) * 100 > 5
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High error rate detected"
          description: "{{ $labels.job }} has error rate of {{ $value }}%"

      # High Response Time
      - alert: HighResponseTime
        expr: |
          histogram_quantile(0.95, 
            rate(http_request_duration_seconds_bucket[5m])
          ) > 2
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High response time"
          description: "95th percentile response time is {{ $value }}s"

      # Service Down
      - alert: ServiceDown
        expr: up{job=~"writers-.*"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Service {{ $labels.job }} is down"
          description: "{{ $labels.job }} has been down for more than 1 minute"
```

ÙØ§ÛŒÙ„ `alerts/infrastructure.yml`:

```yaml
groups:
  - name: infrastructure_alerts
    interval: 30s
    rules:
      # High CPU Usage
      - alert: HighCPUUsage
        expr: |
          100 - (avg by (instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High CPU usage"
          description: "CPU usage is {{ $value }}% on {{ $labels.instance }}"

      # High Memory Usage
      - alert: HighMemoryUsage
        expr: |
          (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) 
          / node_memory_MemTotal_bytes * 100 > 85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage"
          description: "Memory usage is {{ $value }}% on {{ $labels.instance }}"

      # Critical Memory Usage
      - alert: CriticalMemoryUsage
        expr: |
          (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) 
          / node_memory_MemTotal_bytes * 100 > 95
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Critical memory usage"
          description: "Memory usage is {{ $value }}% on {{ $labels.instance }}"

      # Low Disk Space
      - alert: LowDiskSpace
        expr: |
          (node_filesystem_avail_bytes{mountpoint="/"} 
          / node_filesystem_size_bytes{mountpoint="/"}) * 100 < 20
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Low disk space"
          description: "Only {{ $value }}% disk space available on {{ $labels.instance }}"

      # Critical Disk Space
      - alert: CriticalDiskSpace
        expr: |
          (node_filesystem_avail_bytes{mountpoint="/"} 
          / node_filesystem_size_bytes{mountpoint="/"}) * 100 < 10
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Critical disk space"
          description: "Only {{ $value }}% disk space available on {{ $labels.instance }}"
```

## ğŸ“Š Logging Best Practices

### Ø³Ø§Ø®ØªØ§Ø± Log Ø¯Ø± Backend

```python
import logging
import json
from datetime import datetime

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/var/log/writers/backend/app.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# Structured logging
def log_event(event_type: str, data: dict):
    log_data = {
        'timestamp': datetime.utcnow().isoformat(),
        'event_type': event_type,
        'data': data
    }
    logger.info(json.dumps(log_data))

# Ø§Ø³ØªÙØ§Ø¯Ù‡
log_event('user_login', {
    'user_id': 123,
    'ip': '192.168.1.1',
    'success': True
})
```

### Log Levels

- **DEBUG**: Ø§Ø·Ù„Ø§Ø¹Ø§Øª ØªÙØµÛŒÙ„ÛŒ Ø¨Ø±Ø§ÛŒ debugging
- **INFO**: Ø±ÙˆÛŒØ¯Ø§Ø¯Ù‡Ø§ÛŒ Ø¹Ø§Ø¯ÛŒ (login, logout, etc.)
- **WARNING**: Ù…ÙˆØ§Ø±Ø¯ ØºÛŒØ±Ø¹Ø§Ø¯ÛŒ Ú©Ù‡ Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªÙˆØ¬Ù‡ Ø¯Ø§Ø±Ù†Ø¯
- **ERROR**: Ø®Ø·Ø§Ù‡Ø§ÛŒ Ù‚Ø§Ø¨Ù„ handle
- **CRITICAL**: Ø®Ø·Ø§Ù‡Ø§ÛŒ Ø¬Ø¯ÛŒ Ú©Ù‡ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø§Ù‚Ø¯Ø§Ù… ÙÙˆØ±ÛŒ Ø¯Ø§Ø±Ù†Ø¯

## ğŸ” Dashboardâ€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡

### SLI/SLO Dashboard

```yaml
# Service Level Indicators
panels:
  - title: "Availability (SLI)"
    expr: |
      (sum(rate(http_requests_total{status!~"5.."}[30d])) 
      / sum(rate(http_requests_total[30d]))) * 100
    target: 99.9  # SLO

  - title: "Latency (SLI)"
    expr: |
      histogram_quantile(0.95, 
        rate(http_request_duration_seconds_bucket[30d])
      )
    target: 0.5  # 500ms SLO
```

### Business Metrics Dashboard

```yaml
panels:
  - title: "Daily Active Users"
    expr: count(count_over_time({job="writers-backend"} |= "user_login" [24h]))

  - title: "Tasks Created"
    expr: sum(increase(http_requests_total{path="/api/tasks", method="POST"}[24h]))

  - title: "Files Processed"
    expr: sum(increase(celery_task_success_total{task="process_file"}[24h]))
```

## ğŸ”— Integration Ø¨Ø§ CI/CD

```yaml
# Ø¯Ø± .github/workflows/deploy.yml
- name: Check Service Health
  run: |
    curl -f http://localhost:8000/health || exit 1
    
- name: Check Prometheus Targets
  run: |
    curl -s http://localhost:9090/api/v1/targets | jq '.data.activeTargets[] | select(.health!="up")'
    
- name: Alert on Deploy
  uses: 8398a7/action-slack@v3
  with:
    status: ${{ job.status }}
    text: 'Deployment completed'
    webhook_url: ${{ secrets.SLACK_WEBHOOK }}
```

## ğŸ“ Ù†Ú©Ø§Øª Ù…Ù‡Ù…

1. **Retention Policy Ø±Ø§ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯**
   - Prometheus: 15-30 Ø±ÙˆØ²
   - Loki: 7-14 Ø±ÙˆØ²
   - Long-term storage Ø¨Ø§ Thanos ÛŒØ§ Cortex

2. **Alert Fatigue Ø±Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ú©Ù†ÛŒØ¯**
   - ÙÙ‚Ø· alertâ€ŒÙ‡Ø§ÛŒ Ù…Ù‡Ù… Ø±Ø§ ÙØ¹Ø§Ù„ Ú©Ù†ÛŒØ¯
   - Ø§Ø² Grouping Ùˆ Inhibition Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯

3. **Dashboardâ€ŒÙ‡Ø§ Ø±Ø§ Ø³Ø§Ø²Ù…Ø§Ù†â€ŒØ¯Ù‡ÛŒ Ú©Ù†ÛŒØ¯**
   - ÛŒÚ© Dashboard Ú©Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Overview
   - Dashboardâ€ŒÙ‡Ø§ÛŒ Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø³Ø±ÙˆÛŒØ³

4. **Log Sampling Ø¨Ø±Ø§ÛŒ Production**
   - Ù‡Ù…Ù‡ Ù„Ø§Ú¯â€ŒÙ‡Ø§ Ø±Ø§ log Ù†Ú©Ù†ÛŒØ¯
   - Ø§Ø² sampling Ø¨Ø±Ø§ÛŒ high-volume logs Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯

---

Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨ÛŒØ´ØªØ±ØŒ Ø¨Ù‡ Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø±Ø³Ù…ÛŒ [Prometheus](https://prometheus.io/docs/), [Grafana](https://grafana.com/docs/), Ùˆ [Loki](https://grafana.com/docs/loki/) Ù…Ø±Ø§Ø¬Ø¹Ù‡ Ú©Ù†ÛŒØ¯.
